{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIbro Inference Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plaban1981/MLOPS_Tools/blob/main/AIbro_Inference_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Welcome to AIbro Inference Demo!**\n",
        "In this demo, we will show how you can deploy an AI model in 2 minutes. All you need is a formatted ML model repo and an ML application scenario.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Tp4w9bd3Yf3_e1gf1_CdY5aNwZ48mwvm\" width=\"600\" height=\"500\" />"
      ],
      "metadata": {
        "id": "Ut2UU_pJpoUP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Install AIbro"
      ],
      "metadata": {
        "id": "_asfcwLbONdG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W2iZ9_-JpYx1",
        "outputId": "d1ddc938-c967-4a80-ba7c-306806fafa8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting aibro\n",
            "  Downloading aibro-1.1.5-py3-none-any.whl (33 kB)\n",
            "Collecting attrs==21.2.0\n",
            "  Downloading attrs-21.2.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting colorama==0.4.4\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from aibro) (2.10)\n",
            "Collecting build==0.3.1.post1\n",
            "  Downloading build-0.3.1.post1-py2.py3-none-any.whl (13 kB)\n",
            "Collecting tqdm==4.60.0\n",
            "  Downloading tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting websocket-client==0.58.0\n",
            "  Downloading websocket_client-0.58.0-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 9.1 MB/s \n",
            "\u001b[?25hCollecting pytest-mock==3.6.1\n",
            "  Downloading pytest_mock-3.6.1-py3-none-any.whl (12 kB)\n",
            "Collecting args==0.1.0\n",
            "  Downloading args-0.1.0.tar.gz (3.0 kB)\n",
            "Collecting bleach==3.3.0\n",
            "  Downloading bleach-3.3.0-py2.py3-none-any.whl (283 kB)\n",
            "\u001b[K     |████████████████████████████████| 283 kB 63.3 MB/s \n",
            "\u001b[?25hCollecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting pep517==0.10.0\n",
            "  Downloading pep517-0.10.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting bidict==0.21.2\n",
            "  Downloading bidict-0.21.2-py2.py3-none-any.whl (37 kB)\n",
            "Collecting keyring==23.0.1\n",
            "  Downloading keyring-23.0.1-py3-none-any.whl (33 kB)\n",
            "Collecting pluggy==0.13.1\n",
            "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.7/dist-packages (from aibro) (0.5.1)\n",
            "Collecting pre-commit==2.12.1\n",
            "  Downloading pre_commit-2.12.1-py2.py3-none-any.whl (189 kB)\n",
            "\u001b[K     |████████████████████████████████| 189 kB 61.9 MB/s \n",
            "\u001b[?25hCollecting python-dotenv==0.17.1\n",
            "  Downloading python_dotenv-0.17.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting identify==2.2.4\n",
            "  Downloading identify-2.2.4-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting eventlet==0.32.0\n",
            "  Downloading eventlet-0.32.0-py2.py3-none-any.whl (225 kB)\n",
            "\u001b[K     |████████████████████████████████| 225 kB 53.8 MB/s \n",
            "\u001b[?25hCollecting virtualenv==20.4.6\n",
            "  Downloading virtualenv-20.4.6-py2.py3-none-any.whl (7.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.2 MB 31.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from aibro) (1.15.0)\n",
            "Collecting chardet==4.0.0\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 55.3 MB/s \n",
            "\u001b[?25hCollecting typing-extensions==3.7.4.3\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting nodeenv==1.6.0\n",
            "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
            "Collecting pytest==6.2.4\n",
            "  Downloading pytest-6.2.4-py3-none-any.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 63.7 MB/s \n",
            "\u001b[?25hCollecting python-dateutil==2.8.1\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 60.6 MB/s \n",
            "\u001b[?25hCollecting pandas==1.2.5\n",
            "  Downloading pandas-1.2.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 50.5 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata==4.0.1\n",
            "  Downloading importlib_metadata-4.0.1-py3-none-any.whl (16 kB)\n",
            "Collecting toml==0.10.2\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting filelock==3.0.12\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
            "Collecting python-socketio[client]==5.2.1\n",
            "  Downloading python_socketio-5.2.1-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting clint==0.5.1\n",
            "  Downloading clint-0.5.1.tar.gz (29 kB)\n",
            "Collecting packaging==20.9\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting rfc3986==1.4.0\n",
            "  Downloading rfc3986-1.4.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting pkginfo==1.7.0\n",
            "  Downloading pkginfo-1.7.0-py2.py3-none-any.whl (25 kB)\n",
            "Collecting numpy==1.19.5\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 44.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: iniconfig==1.1.1 in /usr/local/lib/python3.7/dist-packages (from aibro) (1.1.1)\n",
            "Collecting pygments==2.9.0\n",
            "  Downloading Pygments-2.9.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 47.0 MB/s \n",
            "\u001b[?25hCollecting cfgv==3.2.0\n",
            "  Downloading cfgv-3.2.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: appdirs==1.4.4 in /usr/local/lib/python3.7/dist-packages (from aibro) (1.4.4)\n",
            "Requirement already satisfied: docutils==0.17.1 in /usr/local/lib/python3.7/dist-packages (from aibro) (0.17.1)\n",
            "Collecting plotly==5.1.0\n",
            "  Downloading plotly-5.1.0-py2.py3-none-any.whl (20.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.6 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting twine==3.4.1\n",
            "  Downloading twine-3.4.1-py3-none-any.whl (34 kB)\n",
            "Collecting requests-toolbelt==0.9.1\n",
            "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting urllib3==1.26.4\n",
            "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
            "\u001b[K     |████████████████████████████████| 153 kB 60.5 MB/s \n",
            "\u001b[?25hCollecting requests==2.25.1\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting objsize==0.3.3\n",
            "  Downloading objsize-0.3.3-py3-none-any.whl (17 kB)\n",
            "Collecting zipp==3.4.1\n",
            "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
            "Collecting pytz==2021.1\n",
            "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
            "\u001b[K     |████████████████████████████████| 510 kB 57.2 MB/s \n",
            "\u001b[?25hCollecting py==1.10.0\n",
            "  Downloading py-1.10.0-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting pyyaml==5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 63.3 MB/s \n",
            "\u001b[?25hCollecting certifi==2020.12.5\n",
            "  Downloading certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 58.7 MB/s \n",
            "\u001b[?25hCollecting python-engineio==4.1.0\n",
            "  Downloading python_engineio-4.1.0-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 146 kB/s \n",
            "\u001b[?25hCollecting greenlet==1.1.1\n",
            "  Downloading greenlet-1.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "\u001b[K     |████████████████████████████████| 143 kB 53.8 MB/s \n",
            "\u001b[?25hCollecting dnspython==2.1.0\n",
            "  Downloading dnspython-2.1.0-py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 59.6 MB/s \n",
            "\u001b[?25hCollecting distlib==0.3.1\n",
            "  Downloading distlib-0.3.1-py2.py3-none-any.whl (335 kB)\n",
            "\u001b[K     |████████████████████████████████| 335 kB 60.9 MB/s \n",
            "\u001b[?25hCollecting readme-renderer==29.0\n",
            "  Downloading readme_renderer-29.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tenacity==7.0.0\n",
            "  Downloading tenacity-7.0.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting SecretStorage>=3.2\n",
            "  Downloading SecretStorage-3.3.2-py3-none-any.whl (15 kB)\n",
            "Collecting jeepney>=0.4.2\n",
            "  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.0\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 42.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring==23.0.1->aibro) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring==23.0.1->aibro) (2.21)\n",
            "Building wheels for collected packages: args, clint\n",
            "  Building wheel for args (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for args: filename=args-0.1.0-py3-none-any.whl size=3318 sha256=dee0c11db7f22fd9c509006e4719b0b3ecfcf8d199018243b09b99ac1b0e8d40\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/9c/cb/445bf22cb64c8cf6a84de63d48ba885470cdf08e77416b6e7a\n",
            "  Building wheel for clint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clint: filename=clint-0.5.1-py3-none-any.whl size=34473 sha256=ad0924c9ee69fd024af01d3a7ff6d1a3ec62db8086442027f44c9e3e17d7f852\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/97/84/72d17bd67a52abe83c647807c3d77dc4d7c1d7709d7077a5f3\n",
            "Successfully built args clint\n",
            "Installing collected packages: zipp, typing-extensions, pyparsing, urllib3, packaging, jeepney, importlib-metadata, cryptography, chardet, certifi, toml, SecretStorage, requests, python-engineio, pygments, py, pluggy, filelock, distlib, bleach, bidict, attrs, websocket-client, virtualenv, tqdm, tenacity, rfc3986, requests-toolbelt, readme-renderer, pyyaml, pytz, python-socketio, python-dateutil, pytest, pkginfo, pep517, numpy, nodeenv, keyring, identify, greenlet, dnspython, colorama, cfgv, args, twine, python-dotenv, pytest-mock, pre-commit, plotly, pandas, objsize, eventlet, clint, build, aibro\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.8.1\n",
            "    Uninstalling zipp-3.8.1:\n",
            "      Successfully uninstalled zipp-3.8.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.3\n",
            "    Uninstalling packaging-21.3:\n",
            "      Successfully uninstalled packaging-21.3\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.12.0\n",
            "    Uninstalling importlib-metadata-4.12.0:\n",
            "      Successfully uninstalled importlib-metadata-4.12.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 3.0.4\n",
            "    Uninstalling chardet-3.0.4:\n",
            "      Successfully uninstalled chardet-3.0.4\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.6.15\n",
            "    Uninstalling certifi-2022.6.15:\n",
            "      Successfully uninstalled certifi-2022.6.15\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Attempting uninstall: py\n",
            "    Found existing installation: py 1.11.0\n",
            "    Uninstalling py-1.11.0:\n",
            "      Successfully uninstalled py-1.11.0\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.7.1\n",
            "    Uninstalling filelock-3.7.1:\n",
            "      Successfully uninstalled filelock-3.7.1\n",
            "  Attempting uninstall: bleach\n",
            "    Found existing installation: bleach 5.0.1\n",
            "    Uninstalling bleach-5.0.1:\n",
            "      Successfully uninstalled bleach-5.0.1\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.4.0\n",
            "    Uninstalling attrs-21.4.0:\n",
            "      Successfully uninstalled attrs-21.4.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.0\n",
            "    Uninstalling tqdm-4.64.0:\n",
            "      Successfully uninstalled tqdm-4.64.0\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 8.0.1\n",
            "    Uninstalling tenacity-8.0.1:\n",
            "      Successfully uninstalled tenacity-8.0.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2022.1\n",
            "    Uninstalling pytz-2022.1:\n",
            "      Successfully uninstalled pytz-2022.1\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Attempting uninstall: pep517\n",
            "    Found existing installation: pep517 0.12.0\n",
            "    Uninstalling pep517-0.12.0:\n",
            "      Successfully uninstalled pep517-0.12.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: greenlet\n",
            "    Found existing installation: greenlet 1.1.2\n",
            "    Uninstalling greenlet-1.1.2:\n",
            "      Successfully uninstalled greenlet-1.1.2\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.5.0\n",
            "    Uninstalling plotly-5.5.0:\n",
            "      Successfully uninstalled plotly-5.5.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "markdown 3.4.1 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 4.0.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.25.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed SecretStorage-3.3.2 aibro-1.1.5 args-0.1.0 attrs-21.2.0 bidict-0.21.2 bleach-3.3.0 build-0.3.1.post1 certifi-2020.12.5 cfgv-3.2.0 chardet-4.0.0 clint-0.5.1 colorama-0.4.4 cryptography-37.0.4 distlib-0.3.1 dnspython-2.1.0 eventlet-0.32.0 filelock-3.0.12 greenlet-1.1.1 identify-2.2.4 importlib-metadata-4.0.1 jeepney-0.8.0 keyring-23.0.1 nodeenv-1.6.0 numpy-1.19.5 objsize-0.3.3 packaging-20.9 pandas-1.2.5 pep517-0.10.0 pkginfo-1.7.0 plotly-5.1.0 pluggy-0.13.1 pre-commit-2.12.1 py-1.10.0 pygments-2.9.0 pyparsing-2.4.7 pytest-6.2.4 pytest-mock-3.6.1 python-dateutil-2.8.1 python-dotenv-0.17.1 python-engineio-4.1.0 python-socketio-5.2.1 pytz-2021.1 pyyaml-5.4.1 readme-renderer-29.0 requests-2.25.1 requests-toolbelt-0.9.1 rfc3986-1.4.0 tenacity-7.0.0 toml-0.10.2 tqdm-4.60.0 twine-3.4.1 typing-extensions-3.7.4.3 urllib3-1.26.4 virtualenv-20.4.6 websocket-client-0.58.0 zipp-3.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "numpy",
                  "pygments",
                  "pyparsing",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  netbase\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 12.7 kB of archives.\n",
            "After this operation, 45.1 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 netbase all 5.4 [12.7 kB]\n",
            "Fetched 12.7 kB in 0s (117 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package netbase.\n",
            "(Reading database ... 155653 files and directories currently installed.)\n",
            "Preparing to unpack .../archives/netbase_5.4_all.deb ...\n",
            "Unpacking netbase (5.4) ...\n",
            "Setting up netbase (5.4) ...\n",
            "\n",
            "Configuration file '/etc/protocols', does not exist on system.\n",
            "Installing new config file as you requested.\n",
            "\n",
            "Configuration file '/etc/rpc', does not exist on system.\n",
            "Installing new config file as you requested.\n",
            "\n",
            "Configuration file '/etc/services', does not exist on system.\n",
            "Installing new config file as you requested.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3.7-dev is already the newest version (3.7.13-1+bionic3).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  python3.7-venv\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 2,516 kB of archives.\n",
            "After this operation, 2,733 kB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.7-venv amd64 3.7.13-1+bionic3 [2,516 kB]\n",
            "Fetched 2,516 kB in 1s (3,593 kB/s)\n",
            "Selecting previously unselected package python3.7-venv.\n",
            "(Reading database ... 155660 files and directories currently installed.)\n",
            "Preparing to unpack .../python3.7-venv_3.7.13-1+bionic3_amd64.deb ...\n",
            "Unpacking python3.7-venv (3.7.13-1+bionic3) ...\n",
            "Setting up python3.7-venv (3.7.13-1+bionic3) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install aibro\n",
        "!sudo apt-get -o Dpkg::Options::=\"--force-confmiss\" install --reinstall netbase # this command is only needed if you meet error: \"OSError: protocol not found\". Colab is in this case.\n",
        "!apt-get install python3.7-dev python3.7-venv # this command is only need for Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Prepare a formatted model repo\n",
        "\n",
        "Source: [https://github.com/AIpaca-Inc/Aibro_examples](https://github.com/AIpaca-Inc/Aibro-examples).\n",
        "\n",
        "The repo should be structured in the following format:\n",
        "\n",
        "repo <br/>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;|\\_\\_&nbsp;[predict.py](#predict-py)<br/>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;|\\_\\_&nbsp;[model](#39-model-39-and-39-data-39-folders)<br/>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;|\\_\\_&nbsp;[data](#39-model-39-and-39-data-39-folders)<br/>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;|\\_\\_&nbsp;[requirement.txt](#requirement-txt)<br/>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;|\\_\\_&nbsp;[other artifacts](#other-artifacts)<br/>\n",
        "\n",
        "### **predict.py**\n",
        "\n",
        "This is the entry point of AIbro.\n",
        "\n",
        "predict.py should contain two methods:\n",
        "\n",
        "1. _load_model()_: this method should load and return your machine learning model from the \"model\" folder. An transformer-based Portuguese to English translator is used in this example repo.\n",
        "\n",
        "```python\n",
        "def load_model():\n",
        "    # Portuguese to English translator\n",
        "    translator = tf.saved_model.load('model')\n",
        "    return translator\n",
        "```\n",
        "\n",
        "2. _run()_: this method used model as the input, load data from the \"data\" folder, predict, then return the inference result.\n",
        "\n",
        "```python\n",
        "def run(model):\n",
        "    fp = open(\"./data/data.json\", \"r\")\n",
        "    data = json.load(fp)\n",
        "    sentence = data[\"data\"]\n",
        "\n",
        "    result = {\"data\": model(sentence).numpy().decode(\"utf-8\")}\n",
        "    return result\n",
        "```\n",
        "\n",
        "**test tip**: predict.py() should be able to return an inference result by:\n",
        "\n",
        "```python\n",
        "run(load_model())\n",
        "```\n",
        "\n",
        "### **\"model\" and \"data\" folders**\n",
        "\n",
        "There is no format restriction on the \"model\" and \"data\" folder as long as the input and output of load_model() and run() from predict.py are correct.\n",
        "\n",
        "### **requirement.txt**\n",
        "\n",
        "Before start deploying the model, packages from requirement.txt are installed to setup the environment.\n",
        "\n",
        "### **Other Artifacts**\n",
        "\n",
        "All other files/folders.\n"
      ],
      "metadata": {
        "id": "1k0DQScLOa-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AIpaca-Inc/Aibro-examples"
      ],
      "metadata": {
        "id": "Hp0KuSWLOemu",
        "outputId": "78e52bf4-8fae-4985-fe03-3c5720867b48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Aibro-examples'...\n",
            "remote: Enumerating objects: 106, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 106 (delta 27), reused 76 (delta 17), pack-reused 19\u001b[K\n",
            "Receiving objects: 100% (106/106), 20.93 MiB | 32.43 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Test the Repo by Dryrun\n",
        "\n",
        "Dryrun locally validates the repo structure and tests if inference result can be successfully returned."
      ],
      "metadata": {
        "id": "za8SLrPiOfIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from aibro.inference import Inference\n",
        "Inference.deploy(\n",
        "    \"./Aibro-examples/tensorflow_transformer\",\n",
        "    dryrun=True,\n",
        ")"
      ],
      "metadata": {
        "id": "ujrDrhVwOmfF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "ff2eb157-15ef-4837-dda1-86288d3d82ae"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mDRYRUN TEST: passed\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DRYRUN TEST: passed'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Create an inference API with one-line code\n",
        "Assume the formatted model repo is saved at path \"./aibro_repo\", we can now use it to create an inference job. The model name should be unique respect to all current [active inference jobs](https://aipaca.ai/inference_jobs) under your profile.\n",
        "\n",
        "In this example, we deployed a public custom model from \"./aibro_repo\" called \"my_fancy_transformer\" on machine type \"c5.large.od\" and used access token for authentication.\n",
        "\n",
        "Once the deployment finished, an API URL is returned with the syntax: </br>\n",
        "\n",
        "- **https://api.aipaca.ai/v1/{username}/{client_id}/{model_name}/predict** </br>\n",
        "\n",
        "**{client_id}**: if your inference job is public, **{client_id}** is filled by \"public\". Otherwise, **{client_id}** should be filled by one of your [clients' ID](#add-clients)."
      ],
      "metadata": {
        "id": "6-tQQ8d6Ol8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from aibro.inference import Inference"
      ],
      "metadata": {
        "id": "d4Qd8jSbDeHL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_url = Inference.deploy(\n",
        "    model_name = \"my_fancy_transformer\",\n",
        "    machine_id_config = \"c5.large.od\",\n",
        "    artifacts_path = \"./Aibro-examples/tensorflow_transformer\",\n",
        "    client_ids = [] # if no clients are specified, the inference job becomes public\n",
        ")"
      ],
      "metadata": {
        "id": "G2R_fMTcMGkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4e82308-9a18-4595-d1f8-4518c603eb8c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already authenticated!\n",
            "Please open https://aipaca.ai/inference_jobs to track job status.\n",
            "[LAUNCHING]: Starting public inference job: inf_8db4b49e-e5eb-47f7-aad6-79ab24841f37\n",
            "[LAUNCHING]: Requesting {'standby': 'c5.large.od'} to be ready...\n",
            "[LAUNCHING]: Started a standby c5.large.od.\n",
            "[LAUNCHING]: c5.large.od server successfully requested, launching and building...\n",
            "[LAUNCHING]: [ Getting server ready in around: 1 minute ]\n",
            "Your {'standby': 'c5.large.od'} instances are now ready 🎉\n",
            "\n",
            "[SENDING]: Serializing your artifacts...\n",
            "\u001b[?25l"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[SENDING]: |>>>>>>>>> | 98.56 % 18.72 / 19.00 MiB [avg: 3.2MiB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[SENDING]: |>>>>>>>>> | 98.57 % 18.73 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.58 % 18.73 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.58 % 18.73 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.59 % 18.73 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.60 % 18.73 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.60 % 18.73 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.61 % 18.73 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.62 % 18.73 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.62 % 18.73 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.63 % 18.74 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.63 % 18.74 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.64 % 18.74 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.65 % 18.74 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.65 % 18.74 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.66 % 18.74 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.67 % 18.74 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.67 % 18.75 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.68 % 18.75 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.69 % 18.75 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.69 % 18.75 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.70 % 18.75 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.71 % 18.75 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.71 % 18.75 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.72 % 18.75 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.73 % 18.75 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.73 % 18.76 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.74 % 18.76 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.75 % 18.76 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 98.75 % 18.76 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.76 % 18.76 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.77 % 18.76 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.77 % 18.76 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.78 % 18.77 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.79 % 18.77 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.79 % 18.77 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.80 % 18.77 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.81 % 18.77 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.81 % 18.77 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.82 % 18.77 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.83 % 18.77 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.83 % 18.77 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.84 % 18.78 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.85 % 18.78 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.85 % 18.78 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.86 % 18.78 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.87 % 18.78 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.87 % 18.78 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.88 % 18.78 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.88 % 18.79 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.89 % 18.79 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.90 % 18.79 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.90 % 18.79 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.91 % 18.79 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.92 % 18.79 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.92 % 18.79 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.93 % 18.79 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.94 % 18.80 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.94 % 18.80 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.95 % 18.80 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.96 % 18.80 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.96 % 18.80 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.97 % 18.80 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.98 % 18.80 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.98 % 18.80 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 98.99 % 18.80 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.00 % 18.81 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.00 % 18.81 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.01 % 18.81 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.02 % 18.81 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.02 % 18.81 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.03 % 18.81 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.04 % 18.81 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.04 % 18.82 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.05 % 18.82 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.06 % 18.82 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.06 % 18.82 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.07 % 18.82 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.08 % 18.82 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.08 % 18.82 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.09 % 18.82 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.10 % 18.82 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.10 % 18.83 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.11 % 18.83 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.12 % 18.83 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.12 % 18.83 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.13 % 18.83 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.13 % 18.83 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.14 % 18.83 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.15 % 18.84 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.15 % 18.84 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.16 % 18.84 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.17 % 18.84 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.17 % 18.84 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.18 % 18.84 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.19 % 18.84 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.19 % 18.84 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.20 % 18.84 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.21 % 18.85 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.21 % 18.85 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.22 % 18.85 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.23 % 18.85 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.23 % 18.85 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.24 % 18.85 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.25 % 18.85 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.25 % 18.86 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.26 % 18.86 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.27 % 18.86 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.27 % 18.86 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.28 % 18.86 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.29 % 18.86 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.29 % 18.86 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.30 % 18.86 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.31 % 18.86 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.31 % 18.87 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.32 % 18.87 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.33 % 18.87 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.33 % 18.87 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.34 % 18.87 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.35 % 18.87 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.35 % 18.87 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.36 % 18.88 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.37 % 18.88 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.37 % 18.88 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.38 % 18.88 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.38 % 18.88 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.39 % 18.88 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.40 % 18.88 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.40 % 18.88 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.41 % 18.89 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.42 % 18.89 / 19.00 MiB [avg: 3.21MiB/s]\r[SENDING]: |>>>>>>>>> | 99.42 % 18.89 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.43 % 18.89 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.44 % 18.89 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.44 % 18.89 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.45 % 18.89 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.46 % 18.89 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.46 % 18.89 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.47 % 18.90 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.48 % 18.90 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.48 % 18.90 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.49 % 18.90 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.50 % 18.90 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.50 % 18.90 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.51 % 18.90 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.52 % 18.91 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.52 % 18.91 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.53 % 18.91 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.54 % 18.91 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.54 % 18.91 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.55 % 18.91 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.56 % 18.91 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.56 % 18.91 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.57 % 18.91 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.58 % 18.92 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.58 % 18.92 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.59 % 18.92 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.60 % 18.92 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.60 % 18.92 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.61 % 18.92 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.62 % 18.92 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.62 % 18.93 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.63 % 18.93 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.64 % 18.93 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.64 % 18.93 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.65 % 18.93 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.65 % 18.93 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.66 % 18.93 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.67 % 18.93 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.67 % 18.93 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.68 % 18.94 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.69 % 18.94 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.69 % 18.94 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.70 % 18.94 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.71 % 18.94 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.71 % 18.94 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.72 % 18.94 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.73 % 18.95 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.73 % 18.95 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.74 % 18.95 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.75 % 18.95 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.75 % 18.95 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.76 % 18.95 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.77 % 18.95 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.77 % 18.95 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.78 % 18.95 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.79 % 18.96 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.79 % 18.96 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.80 % 18.96 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.81 % 18.96 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.81 % 18.96 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.82 % 18.96 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.83 % 18.96 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.83 % 18.96 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.84 % 18.97 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.85 % 18.97 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.85 % 18.97 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.86 % 18.97 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.87 % 18.97 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.87 % 18.97 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.88 % 18.97 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.89 % 18.98 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.89 % 18.98 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.90 % 18.98 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.90 % 18.98 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.91 % 18.98 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.92 % 18.98 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.92 % 18.98 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.93 % 18.98 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.94 % 18.98 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.94 % 18.99 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.95 % 18.99 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.96 % 18.99 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.96 % 18.99 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.97 % 18.99 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.98 % 18.99 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.98 % 18.99 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 99.99 % 19.00 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>> | 100.00 % 19.00 / 19.00 MiB [avg: 3.2MiB/s]\r[SENDING]: |>>>>>>>>>>| 100.00 % 19.00 / 19.00 MiB [avg: 3.2MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mYour Inference API URL: http://api.aipaca.ai/v1/Plaban81/public/my_fancy_transformer/predict\n",
            "\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Inference.list_clients(\"my_fancy_transformer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA5ppJxvFf3G",
        "outputId": "5770e56e-b62f-4748-cc48-0ebc82172476"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already authenticated!\n",
            "\u001b[32mCurrent client ids: []\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_uri"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cPzZujyu9FYd",
        "outputId": "3264bc0c-5e49-4b28-e66f-7f059ab75e3b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'http://api.aipaca.ai/v1/Plaban81/public/my_fancy_transformer/predict'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to Test an Aibro API"
      ],
      "metadata": {
        "id": "OWqqhy6zPQb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        " \n",
        "review = {\"data\": \"India\"}\n",
        " \n",
        "prediction = requests.post(\n",
        "   \"http://api.aipaca.ai/v1/Plaban81/public/my_fancy_transformer/predict\",\n",
        "   data=review,\n",
        ")\n",
        " \n",
        "result = prediction.text\n",
        " \n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzZCIs_-O7YT",
        "outputId": "34883cb6-869c-4ba7-a435-ab632a1db553"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data': 'this is the first book i did .'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Test a Aibro API with curl\n",
        "Copy your API URL into `{{api_url}}`. For instance, my `api_url` is http://api.aipaca.ai/v1/yuqil725/public/my_fancy_transformer/predict\n",
        "\n",
        "The syntax when using `curl` depends on the file type in the `data` folder.\n",
        "\n",
        "| Data Type | syntax                                                                                                       |\n",
        "| --------- | ------------------------------------------------------------------------------------------------------------ |\n",
        "| json      | curl -X POST {{aibro url}} -d '{\"your\": \"data\"}'<br/>curl -X POST {{aibro url}} -F file=@'path/to/json/file' |\n",
        "| txt       | curl -X POST {{aibro url}} -d 'your data'<br/>curl -X POST {{aibro url}} -F file=@'path/to/txt/file'         |\n",
        "| csv       | curl -X POST {{aibro url}} -F file=@'path/to/csv/file'                                                       |\n",
        "| others    | curl -X POST {{aibro url}} -F file=@'path/to/zip/file'                                                       |\n",
        "\n",
        "You may have observed some patterns from the syntax lookup table above:\n",
        "\n",
        "- If the data type is `json` or `txt`, you could use `-d` flag to post the string data directly.\n",
        "- If the data type is one of `json`, `txt`, or `csv`, you could use `-F` flag to post the data file by path.\n",
        "- If the data type is not one of `json`, `txt`, or `csv`, you could zip the entire `data` folder then post the data file by the zip path.\n",
        "\n",
        "_Tips_: if your inference time is over one minute, it is recommended to either reduce the data size or increase the `--keepalive-time` value when using `curl`."
      ],
      "metadata": {
        "id": "epTblILqJBXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X POST {{api_url}} -d '{\"data\": \"Olá\"}'"
      ],
      "metadata": {
        "id": "Y4oOl55zIegy",
        "outputId": "b6d1edea-c6ab-439f-d370-99c9b2a76a8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "curl: (3) [globbing] nested brace in column 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Limit API Access to Specific Clients (Optional)\n",
        "\n",
        "As the API owner, you probably don't receive overwhelming API requests from everywhere. To avoid this trouble, you could give every client an unique client id, which is going to used in API endpoint (as the shown syntax in the step 4). If no client id was added, this inference job would be public by default."
      ],
      "metadata": {
        "id": "qzRabSmVK7ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from aibro.inference import Inference\n",
        "Inference.update_clients(\n",
        "    job_id = \"inf_ec49d03f-67ba-44e8-ac3c-c6bc81ca630c\",\n",
        "    add_client_ids = [\"client_3\", \"client_4\"]\n",
        ")"
      ],
      "metadata": {
        "id": "QWATAV_7LEN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4efd7a56-391a-40df-8607-ff1a2d56c99a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already authenticated!\n",
            "Update client succeeded!\n",
            "\u001b[32mCurrent client ids: ['client_1', 'client_2', 'client_3', 'client_4']\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['client_1', 'client_2', 'client_3', 'client_4']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FSgxBOx9T603",
        "outputId": "cace8126-613d-412f-a9fe-a9be19731b51"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'http://api.aipaca.ai/v1/Plaban81/public/my_fancy_transformer/predict'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run a Private Prediction\n",
        "\n",
        "You could fill in {client_id} by either \"client_1\" or \"client_2\" now. \"public\" is not going to work any more."
      ],
      "metadata": {
        "id": "f47NbwSWXfG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -d '{\"data\": \"Olá\"}' -X POST {{api_url}}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WLyk-olXjeX",
        "outputId": "20107965-87f5-412b-c10e-e09193526e7d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "curl: (3) [globbing] nested brace in column 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -d '{\"data\": \"Olá\"}' -X POST {{api_url}}"
      ],
      "metadata": {
        "id": "_9PIenZqCUZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1ccef0f-458f-4b25-c489-69bca477d237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"data\":\"hello , hello , hello ,\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Complete Job\n",
        "\n",
        "Once the inference job is no longer used, to avoid unnecessary cost, please remember to close it by `Inference.complete()`."
      ],
      "metadata": {
        "id": "v55NNLSYLEDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Inference.complete(job_id=\"inf_ec49d03f-67ba-44e8-ac3c-c6bc81ca630c\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GY7StKzCZ0q",
        "outputId": "c31c9cec-494d-4a1c-87d3-3f5beb4bca14"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already authenticated!\n",
            "Inference job inf_ec49d03f-67ba-44e8-ac3c-c6bc81ca630c, with model my_fancy_transformer, successfully completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Inference.complete(job_id=\"inf_8db4b49e-e5eb-47f7-aad6-79ab24841f37\")"
      ],
      "metadata": {
        "id": "OtQmiHtOGaqz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdb0d6d7-814d-46f6-f0e4-bad630d0b343"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already authenticated!\n",
            "Inference job inf_8db4b49e-e5eb-47f7-aad6-79ab24841f37, with model my_fancy_transformer, successfully completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Inference.complete(job_id=\"inf_35a39b71-49d7-4561-87db-aca2ab5042c1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDaqKRNqZ7m8",
        "outputId": "d5dddba5-d66a-4c32-d433-b86e159e7733"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already authenticated!\n",
            "Inference job inf_35a39b71-49d7-4561-87db-aca2ab5042c1, with model my_fancy_transformer, successfully completed.\n"
          ]
        }
      ]
    }
  ]
}